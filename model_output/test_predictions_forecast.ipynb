{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4192,"status":"ok","timestamp":1684843916622,"user":{"displayName":"ARNE BERRESHEIM","userId":"06065091921129973079"},"user_tz":-120},"id":"z_D3y_FKHLgH","outputId":"05824e3d-11cf-4525-ca2a-48ed14b3ab30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#imports\n","#from google.colab import drive\n","from scipy.io import loadmat\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import math\n","import os\n","import time\n","import datetime\n","import itertools\n","import h5py\n","import matplotlib.dates as mdates\n","\n","\n","# define the data location and load data\n","cwd = os.getcwd()\n","pardir = os.path.dirname(cwd)\n","\n","#### commented for google drive\n","#drive.mount('/content/drive')\n","#pardir = \"/content/drive/MyDrive/Stanford-solar-forecasting-dataset/\"\n","\n","\n","data_folder = os.path.join(pardir,\"data\")#,\"data_forecast\")\n","data_path = os.path.join(data_folder, \"2017_2019_images_pv_processed_forecast.hdf5\") #forecast_dataset\n","output_folder = oc.path.join(pardir, \"model_output/SUNSET_forecast/\")"]},{"cell_type":"markdown","metadata":{"id":"Ef760GitHO_L"},"source":["### Import data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_p8rwPPOHWTf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684843916624,"user_tz":-120,"elapsed":22,"user":{"displayName":"ARNE BERRESHEIM","userId":"06065091921129973079"}},"outputId":"7f505f7e-e4d0-45b3-b733-e895baf7d17d"},"outputs":[{"output_type":"stream","name":"stdout","text":["image side length: 64\n","number of color channels: 3\n","input image dimension: [64, 64, 3]\n","sun_pos dimension: 2\n","sampi dimension: 1\n"]}],"source":["times_trainval = np.load(data_dir+\"times_trainval.npy\", allow_pickle=True)\n","f = h5py.File(data_dir+'2017_2019_images_pv_processed_forecast.hdf5', 'r')\n","test = f['test']\n","pv_log = test['pv_log']\n","images_log = test['images_log']\n","pv_log = pv_log[:]\n","\n","# get the input dimension for constructing the model\n","img_side_len = f['trainval']['images_log'].shape[1]\n","num_color_channel = f['trainval']['images_log'].shape[3]\n","image_input_dim = [img_side_len,img_side_len,num_color_channel]\n","#MYEDIT: getting the dim of the sun_pos\n","sun_pos_dim = f['trainval']['sun_pos'].shape[1]\n","sampi_dim = f['trainval']['sampi'].shape[1]\n","\n","print(\"image side length:\", img_side_len)\n","print(\"number of color channels:\", num_color_channel)\n","print(\"input image dimension:\", image_input_dim)\n","#MYEDIT\n","print(\"sun_pos dimension:\", sun_pos_dim)\n","print(\"sampi dimension:\", sampi_dim)\n","\n","\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"vQV7tiuBlqcY"},"source":["### Model architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Y2xJpXpalqcY"},"outputs":[],"source":["# define model characteristics\n","num_filters = 24\n","kernel_size = [3,3]\n","pool_size = [2,2]\n","strides = 2\n","dense_size = 1024\n","drop_rate = 0.4\n","\n","# define training time parameters\n","num_epochs = 200 #(The maximum epoches set to 200 and there might be early stopping depends on validation loss)\n","num_fold = 10 # 10-fold cross-validation\n","batch_size = 256\n","learning_rate = 3e-06"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_4D4IATlqcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684843917412,"user_tz":-120,"elapsed":807,"user":{"displayName":"ARNE BERRESHEIM","userId":"06065091921129973079"}},"outputId":"3bc3a7ae-476b-481f-8cd0-2e602517a614"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_7 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 64, 64, 24)   672         ['input_7[0][0]']                \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 64, 64, 24)  96          ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 24)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 32, 32, 48)   10416       ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 32, 32, 48)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 48)  0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," flatten_2 (Flatten)            (None, 12288)        0           ['max_pooling2d_5[0][0]']        \n","                                                                                                  \n"," input_8 (InputLayer)           [(None, 2)]          0           []                               \n","                                                                                                  \n"," input_9 (InputLayer)           [(None, 1)]          0           []                               \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 12291)        0           ['flatten_2[0][0]',              \n","                                                                  'input_8[0][0]',                \n","                                                                  'input_9[0][0]']                \n","                                                                                                  \n"," dense_6 (Dense)                (None, 1024)         12587008    ['concatenate_2[0][0]']          \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 1024)         0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 1024)         1049600     ['dropout_4[0][0]']              \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 1024)         0           ['dense_7[0][0]']                \n","                                                                                                  \n"," dense_8 (Dense)                (None, 1)            1025        ['dropout_5[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 13,649,009\n","Trainable params: 13,648,865\n","Non-trainable params: 144\n","__________________________________________________________________________________________________\n"]}],"source":["# define the model architecture using tf.keras API\n","def sunset_model():\n","    ## input\n","    ### input image logs with shape (64,64,3)\n","    x_in = keras.Input(shape=image_input_dim)\n","    ###MYEDIT: input of the sun position with shape (2) and sampi with shape (1)\n","    x2_in = keras.Input(shape=sun_pos_dim)\n","    x3_in = keras.Input(shape=sampi_dim)\n","\n","    ## 1st convolution block\n","    x = keras.layers.Conv2D(num_filters,kernel_size,padding=\"same\",activation='relu')(x_in)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D(pool_size, strides)(x)\n","\n","    ## 2nd convolution block\n","    x = keras.layers.Conv2D(num_filters*2,kernel_size,padding=\"same\",activation='relu')(x)\n","    x = keras.layers.BatchNormalization()(x)\n","    x = keras.layers.MaxPooling2D(pool_size, strides)(x)\n","\n","    ## two fully connected nets\n","    x = keras.layers.Flatten()(x)\n","    #MYEDIT: concatenating the sun_pos and sampi\n","    x = keras.layers.Concatenate(axis=1)([x, x2_in, x3_in])\n","\n","    x = keras.layers.Dense(dense_size, activation='relu')(x)\n","    x = keras.layers.Dropout(drop_rate)(x)\n","    x = keras.layers.Dense(dense_size, activation='relu')(x)\n","    x = keras.layers.Dropout(drop_rate)(x)\n","\n","    ## regression to prediction target\n","    y_out = keras.layers.Dense(units=1)(x)\n","\n","    # construct the model MYEDIT: adding the sun_pos as input\n","    model = keras.Model(inputs=[x_in, x2_in, x3_in],outputs=y_out)\n","\n","    return model\n","\n","# show model architecture\n","sunset_model().summary()"]},{"cell_type":"markdown","metadata":{"id":"mujSLF_slruc"},"source":["### Model testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mL5LxK9lruc"},"outputs":[],"source":["# load testing data\n","times_test = np.load(os.path.join(data_folder,\"times_test.npy\"),allow_pickle=True)\n","print(\"times_test.shape:\", times_test.shape)\n","\n","with h5py.File(data_path,'r') as f:\n","\n","    # read in the data\n","    images_log_test = f['test']['images_log'][...]\n","    pv_log_test = f['test']['pv_log'][...]\n","    pv_pred_test = f['test']['pv_pred'][...]\n","\n","# process image data\n","images_log_test = np.transpose(images_log_test,axes=[0,2,3,1,4])\n","images_log_test = np.reshape(images_log_test, [images_log_test.shape[0],images_log_test.shape[1],images_log_test.shape[2],-1])\n","images_log_test = (images_log_test/255.0).astype('float32')\n","    \n","print(\"images_log_test.shape:\",images_log_test.shape)\n","print(\"pv_log_test.shape:\",pv_log_test.shape)\n","print(\"pv_pred_test.shape:\",pv_pred_test.shape)\n","\n","print('image ex ', images_log_test[0,0])\n","print('pv log ex ', pv_log_test[0,0])\n","print('pv pred ex ', pv_pred_test[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"GP8Sb3bplruc"},"outputs":[],"source":["# evaluate model on the test set and generate predictions\n","loss = np.zeros((num_fold,len(times_test)))\n","prediction = np.zeros((num_fold,len(times_test)))\n","\n","for i in range(num_fold):\n","    # define model path\n","    print(\"loading repetition {0} model ...\".format(i+1))\n","    model_path = os.path.join(output_folder,'repetition_'+str(i+1),'best_model_repitition_'+str(i+1)+'.h5')\n","    # load the trained model\n","    model = keras.models.load_model(model_path)\n","    \n","    # model evaluation\n","    print(\"evaluating performance for the model\".format(i+1))\n","    loss[i] = model.evaluate(x=[images_log_test,pv_log_test], y=pv_pred_test, batch_size=200, verbose=1)\n","    \n","    # generate prediction\n","    print(\"generating predictions for the model\".format(i+1))\n","    prediction[i] = np.squeeze(model.predict([images_log_test,pv_log_test], batch_size=200, verbose=1))\n","\n","# saving predictions from each model\n","np.save(os.path.join(output_folder,'test_predictions.npy'),prediction)\n","\n","# using the ensemble mean of the 10 models as the final prediction \n","print('-'*50)\n","print(\"model ensembling ...\")\n","prediction_ensemble = np.mean(prediction,axis=0)\n","loss_ensemble = np.sqrt(np.mean((prediction_ensemble-pv_pred_test)**2))\n","print(\"the test set RMSE is {0:.3f} for the ensemble model\".format(loss_ensemble))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLQGx3LHlrud"},"outputs":[],"source":["# formulate sunny and cloudy test days\n","sunny_dates = [(2017,9,15),(2017,10,6),(2017,10,22),\n","               (2018,2,16),(2018,6,12),(2018,6,23),\n","               (2019,1,25),(2019,6,23),(2019,7,14),(2019,10,14)]\n","cloudy_dates = [(2017,6,24),(2017,9,20),(2017,10,11),\n","                (2018,1,25),(2018,3,9),(2018,10,4),\n","                (2019,5,27),(2019,6,28),(2019,8,10),(2019,10,19)]\n","sunny_dates_test = [datetime.date(day[0],day[1],day[2]) for day in sunny_dates]\n","cloudy_dates_test = [datetime.date(day[0],day[1],day[2]) for day in cloudy_dates]\n","\n","dates_test = np.asarray([times.date() for times in times_test])\n","\n","## generate mask for the sunny days\n","mask = np.zeros(len(pv_pred_test),dtype=bool)\n","for i in sunny_dates_test:\n","    mask[np.where(dates_test==i)[0]]=1\n","\n","## apply the mask to the dataset\n","times_test_sunny = times_test[mask]\n","pv_pred_test_sunny = pv_pred_test[mask]\n","pv_log_test_sunny = pv_log_test[mask]\n","prediction_ensemble_sunny = prediction_ensemble[mask]\n","print(\"times_test_sunny.shape:\",times_test_sunny.shape)\n","\n","times_test_cloudy = times_test[~mask]\n","pv_pred_test_cloudy = pv_pred_test[~mask]\n","pv_log_test_cloudy = pv_log_test[~mask]\n","prediction_ensemble_cloudy = prediction_ensemble[~mask]\n","print(\"times_test_cloudy.shape:\",times_test_cloudy.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiDUp_eOlrud"},"outputs":[],"source":["# RMSE for sunny and cloudy days individually\n","rmse_sunny = np.sqrt(np.mean(np.square((prediction_ensemble_sunny-pv_pred_test_sunny))))\n","rmse_cloudy = np.sqrt(np.mean(np.square((prediction_ensemble_cloudy-pv_pred_test_cloudy))))\n","rmse_overall = np.sqrt((rmse_sunny**2*len(pv_pred_test_sunny)+rmse_cloudy**2*len(pv_pred_test_cloudy))/(len(pv_pred_test)))\n","\n","print(\"test set sunny days RMSE: {0:.3f}\".format(rmse_sunny))\n","print(\"test set cloudy days RMSE: {0:.3f}\".format(rmse_cloudy))\n","print(\"test set overall RMSE: {0:.3f}\".format(rmse_overall))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dh7RAKDlrud"},"outputs":[],"source":["# MAE for sunny and cloudy days individually\n","mae_sunny = np.mean(np.abs((prediction_ensemble_sunny-pv_pred_test_sunny)))\n","mae_cloudy = np.mean(np.abs((prediction_ensemble_cloudy-pv_pred_test_cloudy)))\n","mae_overall = (mae_cloudy*len(pv_pred_test_cloudy) + mae_sunny*len(pv_pred_test_sunny))/(len(pv_pred_test))\n","\n","print(\"test set sunny days MAE: {0:.3f}\".format(mae_sunny))\n","print(\"test set cloudy days MAE: {0:.3f}\".format(mae_cloudy))\n","print(\"test set overall MAE: {0:.3f}\".format(mae_overall))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrvsF6Ailrud"},"outputs":[],"source":["# forecast skill for sunny and cloudy days individually\n","## calculate the rmse of persistent model\n","from Relative_op_func import *\n","\n","ntimes = times_test.shape[0]\n","per_prediction = np.zeros(ntimes)\n","for i in range(ntimes):\n","    CSI_cur, P_theo_cur = Relative_output(times_test[i],pv_log_test[i][0])\n","    CSI, P_theo_pred = Relative_output(times_test[i]+datetime.timedelta(minutes=15),pv_pred_test[i])\n","    per_prediction[i] = CSI_cur*P_theo_pred\n","\n","per_prediction_sunny = per_prediction[mask]\n","per_prediction_cloudy = per_prediction[~mask]\n","\n","per_rmse_sunny = np.sqrt(np.mean(np.square((per_prediction_sunny-pv_pred_test_sunny))))\n","per_rmse_cloudy = np.sqrt(np.mean(np.square((per_prediction_cloudy-pv_pred_test_cloudy))))\n","per_rmse_overall = np.sqrt((per_rmse_sunny**2*len(pv_pred_test_sunny)+per_rmse_cloudy**2*len(pv_pred_test_cloudy))/(len(pv_pred_test)))\n","print(\"test set sunny days RMSE persistence: {0:.3f}\".format(per_rmse_sunny))\n","print(\"test set cloudy days RMSE persistence: {0:.3f}\".format(per_rmse_cloudy))\n","print(\"test set overall RMSE persistence: {0:.3f}\".format(per_rmse_overall))\n","\n","## calculate the forecasting skills\n","forecast_skill_sunny = 1 - rmse_sunny/per_rmse_sunny\n","forecast_skill_cloudy = 1 - rmse_cloudy/per_rmse_cloudy\n","forecast_skill_overall = 1 - rmse_overall/per_rmse_overall\n","print(\"test set sunny days forecast skill: {0:.2f}%\".format(forecast_skill_sunny*100))\n","print(\"test set cloudy days forecast skill: {0:.2f}%\".format(forecast_skill_cloudy*100))\n","print(\"test set overall forecast skill: {0:.2f}%\".format(forecast_skill_overall*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBG3gu-wlrue"},"outputs":[],"source":["# visualization of forecast predictions\n","dates_test = np.array([dtinfo.date() for dtinfo in times_test])\n","hours_test = np.array([dtinfo.time() for dtinfo in times_test])\n","\n","f,axarr = plt.subplots(10,2,sharex=False, sharey = True)\n","xfmt = mdates.DateFormatter('%H')\n","fmt_date = datetime.date(2000,1,1)\n","\n","green = '#8AB8A7'\n","red = '#B83A4B'\n","blue = '#67AFD2'\n","grey =  '#B6B1A9'\n","\n","for i,date in enumerate(sunny_dates_test):\n","    ax = axarr[i,0]\n","    date_mask = (dates_test == date)\n","    hours_xaxis= [datetime.datetime.combine(fmt_date, hour) for hour in hours_test[date_mask]] \n","    \n","    rmse = np.sqrt(np.mean(np.square((pv_pred_test[date_mask]-prediction_ensemble[date_mask]))))\n","    mae = np.mean(np.abs((pv_pred_test[date_mask]-prediction_ensemble[date_mask])))\n","    per_rmse = np.sqrt(np.mean(np.square((pv_pred_test[date_mask]-per_prediction[date_mask]))))\n","    fs = (1 - rmse/per_rmse)*100\n","    \n","    ax.plot(hours_xaxis, pv_pred_test[date_mask], linewidth = 1,color=grey)\n","    ax.fill_between(hours_xaxis, 0, pv_pred_test[date_mask], color=grey, alpha=.2, label = 'Ground truth')\n","    ax.plot(hours_xaxis, prediction_ensemble[date_mask],linewidth = 1,label = 'SUNSET forecast',color=red,markerfacecolor=\"None\")\n","    ax.set_ylabel('PV output (kW)')\n","    ax.xaxis.set_major_formatter(xfmt)\n","    ax.text(0.75,0.85,'Sunny_'+str(i+1), transform=ax.transAxes)\n","    ax.text(0.05,0.65,\"RMSE: {0:.2f}\\nMAE: {1:.2f}\\nFS: {2:.2f}%\".format(rmse,mae,fs),transform=ax.transAxes)\n","\n","for i,date in enumerate(cloudy_dates_test):\n","    ax = axarr[i,1]\n","    date_mask = (dates_test == date)\n","    hours_xaxis= [datetime.datetime.combine(fmt_date, hour) for hour in hours_test[date_mask]] \n","    \n","    rmse = np.sqrt(np.mean(np.square((pv_pred_test[date_mask]-prediction_ensemble[date_mask]))))\n","    mae = np.mean(np.abs((pv_pred_test[date_mask]-prediction_ensemble[date_mask])))\n","    per_rmse = np.sqrt(np.mean(np.square((pv_pred_test[date_mask]-per_prediction[date_mask]))))\n","    fs = (1 - rmse/per_rmse)*100\n","    \n","    ax.plot(hours_xaxis, pv_pred_test[date_mask], linewidth = 1,color=grey)\n","    ax.fill_between(hours_xaxis, 0, pv_pred_test[date_mask], color=grey, alpha=.2, label = 'Ground truth')\n","    ax.plot(hours_xaxis, prediction_ensemble[date_mask],linewidth = 1,label = 'SUNSET forecast',color=red,markerfacecolor=\"None\")\n","    ax.set_ylabel('PV output (kW)')\n","    ax.xaxis.set_major_formatter(xfmt)\n","    ax.text(0.75,0.85,'Cloudy_'+str(i+1), transform=ax.transAxes)\n","    ax.text(0.05,0.65,\"RMSE: {0:.2f}\\nMAE: {1:.2f}\\nFS: {2:.2f}%\".format(rmse,mae,fs),transform=ax.transAxes)\n","\n","    \n","axarr[0,0].set_ylim(0, 30)\n","axarr[0,0].legend(bbox_to_anchor= [1.15,1.3], loc = 'upper center', ncol = 3)\n","axarr[-1,0].set_xlabel('Hour of day')\n","axarr[-1,1].set_xlabel('Hour of day')\n","\n","f.set_size_inches(10,25)    \n","plt.show()  "]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+h0zlUzbxQW7AhOPkcafe"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}